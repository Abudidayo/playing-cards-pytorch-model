{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (f\"Using device: {device}\")\n",
    "\n",
    "devNumber=torch.cuda.current_device()\n",
    "print(f\"Current Device Number: {devNumber}\")\n",
    "\n",
    "devName=torch.cuda.get_device_name(devNumber)\n",
    "print(f\"Device Name: {devName}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3a017",
   "metadata": {},
   "source": [
    "### Download Playing Cards Dataset (Around 500mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe754823",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "ZIP_PATH = \"data/cards.zip\"\n",
    "\n",
    "# Train data directory\n",
    "data_dir= \"data/train\"\n",
    "\n",
    "# Create folder\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Downloading dataset...\")\n",
    "response = requests.get(\"https://www.kaggle.com/api/v1/datasets/download/gpiosenka/cards-image-datasetclassification\", stream=True)\n",
    "\n",
    "# Save zip file\n",
    "with open(ZIP_PATH, \"wb\") as f:\n",
    "        for chunk in tqdm(response.iter_content(chunk_size=8192), desc=\"Downloading\", unit=\"MB\"):\n",
    "            f.write(chunk)\n",
    "\n",
    "# Extract zip file\n",
    "print(\"Extracting dataset...\")\n",
    "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR)\n",
    "\n",
    "# Remove zip file\n",
    "os.remove(ZIP_PATH)\n",
    "\n",
    "print(\"Dataset ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6b13f",
   "metadata": {},
   "source": [
    "### Print version numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5175c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"System Version:\", sys.version)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"Timm Version:\", timm.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e3254",
   "metadata": {},
   "source": [
    "# Step 1: Creating a PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b44604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayingCardDataSet(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PlayingCardDataSet(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[5000]\n",
    "print(label)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67163e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\n",
    "print(target_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943729f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = PlayingCardDataSet(data_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d130ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401b4c4",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for images, labels in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e85ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0b7c5",
   "metadata": {},
   "source": [
    "# Step 2: PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCardClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=53):\n",
    "        super(SimpleCardClassifier, self).__init__()\n",
    "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "\n",
    "        enet_out_size = 1280\n",
    "        # Make a classifier\n",
    "        self.classifier = nn.Linear(enet_out_size, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCardClassifier(num_classes=53)\n",
    "print(str(model)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_out = model(images)\n",
    "example_out.shape # [Batch size, num_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6f63d",
   "metadata": {},
   "source": [
    "# Step 3: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5677436",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(example_out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36acb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_folder = \"data/train\"\n",
    "valid_folder = \"data/valid\"\n",
    "test_folder = \"data/test\"\n",
    "\n",
    "train_dataset = PlayingCardDataSet(train_folder, transform=transform)\n",
    "valid_dataset = PlayingCardDataSet(valid_folder, transform=transform)\n",
    "test_dataset = PlayingCardDataSet(test_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1497b6",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "train_losses, val_losses= [], []\n",
    "\n",
    "model = SimpleCardClassifier(num_classes=53)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training Loader\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader, desc=\"Validation Loader\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "    val_loss = running_loss / len(valid_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05147731",
   "metadata": {},
   "source": [
    "# Visualize training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image, transform(image).unsqueeze(0)\n",
    "\n",
    "# Predict using the model\n",
    "def predict(model, image_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    return probabilities.cpu().numpy().flatten()\n",
    "\n",
    "# Visualization\n",
    "def visualize_predictions(original_image, probabilities, class_names):\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Display image\n",
    "    axarr[0].imshow(original_image)\n",
    "    axarr[0].axis(\"off\")\n",
    "    \n",
    "    # Display predictions\n",
    "    axarr[1].barh(class_names, probabilities)\n",
    "    axarr[1].set_xlabel(\"Probability\")\n",
    "    axarr[1].set_title(\"Class Predictions\")\n",
    "    axarr[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "test_image = \"5_of_spades.jpg\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "original_image, image_tensor = preprocess_image(test_image, transform)\n",
    "probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "# Assuming dataset.classes gives the class names\n",
    "class_names = dataset.classes \n",
    "visualize_predictions(original_image, probabilities, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
